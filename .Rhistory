setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/retro2")
library(rJava, lib.loc = "C:/Users/User/AppData/Local/R/win-library/4.3")
library(tm)
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(tidytext)
library(dplyr)
library(wordcloud)
library(readxl)
library(xlsx)
library(htmlwidgets, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(topicmodels)
library(LDAvis)
library(ggplot2)
library(stringi, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(stringr, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(servr)
library(Rmpfr)
news_nov_body<-read_excel("retro.xlsx", sheet="sheet" ,range="Q2:Q2097", col_names=TRUE,col_types='guess', na="NA")
news_nov_body_line<-as.matrix(news_nov_body)
news_nov_body_line<-gsub(",","",news_nov_body_line)
news_nov_corpus<-Corpus(VectorSource(news_nov_body_line))
news_nov_dtm2<-DocumentTermMatrix(news_nov_corpus, control=list(removePunctuation=TRUE, removeNumbers=TRUE,WordLengths=c(4,40), weighting=weightTf))
Encoding(news_nov_dtm2$dimnames$Terms) = 'UTF-8'
harmonicMean <- function(logLikelihoods, precision=2000L) {
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods, prec=precision) + llMed))))
}
seqk <- seq(2, 40, 1)
burnin <- 1000
iter <- 1000
keep <- 50
fitted_many <- lapply(seqk, function(k) LDA(news_nov_dtm2, k=k, method="Gibbs",
control=list(burnin=burnin, iter=iter, keep=keep)))
logLiks_many <- lapply(fitted_many, function(L) L@logLiks[-c(1:(burnin/keep))])
fitted_many <- lapply(seqk, function(k) LDA(news_nov_dtm2, k=k, method="Gibbs",
control=list(burnin=burnin, iter=iter, keep=keep)))
setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/retro2")
library(xlsx)
library(tidytext)
library(rJava, lib.loc = "C:/Users/User/AppData/Local/R/win-library/4.3")
detach("package:rJava", unload = TRUE)
library(rJava, lib.loc = "C:/Users/User/AppData/Local/R/win-library/4.3")
.libPaths()
.libPaths("C:/rtools42")
detach("package:rJava", unload = TRUE)
library(rJava)
library(tm)
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(dplyr)
setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/retro2")
library(xlsx)
library(tidytext)
library(rJava)
library(tm)
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
.libPaths()
.libPaths("C:/Program Files/R/R-4.3.1/library")
library(KoNLP)
.libPaths()
.libPaths("C:/rtools42")
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
install("KoNLP")
install.packages("KoNLP")
library(KoNLP, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:KoNLP", unload = TRUE)
library(KoNLP)
install.packages("KoNLP")
library(KoNLP)
library(dplyr)
library(wordcloud)
library(readxl)
library(htmlwidgets, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:htmlwidgets", unload = TRUE)
library(htmlwidgets)
detach("package:htmlwidgets", unload = TRUE)
library(htmlwidgets)
library(topicmodels)
library(LDAvis)
library(ggplot2)
library(stringi, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(stringr)
.libPaths()
.libPaths("C:/rtools42")
library(rJava)
library(tm)
library(KoNLP)
remove.packages("KoNLP", lib="C:/Program Files/R/R-4.3.1/library")
remove.packages("KoNLP")
install.packages("C:/Users/User/Saved Games/Downloads/KoNLP_0.80.2.tar.gz", repos = NULL, type = "source")
library(KoNLP)
useNIADic()
detach("package:KoNLP", unload = TRUE)
library(KoNLP)
library(tidytext)
library(dplyr)
library(wordcloud)
library(readxl)
library(xlsx)
library(htmlwidgets)
library(topicmodels)
library(LDAvis)
library(ggplot2)
library(stringi, lib.loc = "C:/Program Files/R/R-4.3.1/library")
library(stringr)
detach("package:stringr", unload = TRUE)
library(stringr, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:stringr", unload = TRUE)
install.packages("stringr")
install.packages("stringr")
library(stringr)
detach("package:stringr", unload = TRUE)
library(stringr, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:stringr", unload = TRUE)
library(stringr)
detach("package:stringr", unload = TRUE)
.libPaths("C:/rtools42")
.libPaths()
.libPaths("C:/rtools42")
.libPaths()
library(reshape2)
.libPaths("C:/Program Files/R/R-4.3.1/library")
.libPaths()
.libPaths("C:/rtools42")
.libPaths()
library(rJava)
library(tm)
library(KoNLP)
library(tidytext)
library(dplyr)
library(wordcloud)
library(readxl)
library(xlsx)
library(htmlwidgets)
remove.packages("htmlwidgets", lib="C:/Program Files/R/R-4.3.1/library")
library(topicmodels)
library(LDAvis)
library(ggplot2)
library(stringi, lib.loc = "C:/Program Files/R/R-4.3.1/library")
remove.packages("stringi", lib="C:/Program Files/R/R-4.3.1/library")
install("stringi")
install.packages("stringi")
install.packages("stringi")
install.packages("stringi")
install.packages("stringi")
library(stringi)
detach("package:stringi", unload = TRUE)
library(stringi)
library(stringr, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:stringr", unload = TRUE)
remove.packages("stringr", lib="C:/Program Files/R/R-4.3.1/library")
library(stringr)
library(servr)
library(Rmpfr)
setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/뉴트로")
news_nov_body<-read_excel("newtro.xlsx", sheet="sheet" ,range="Q2:Q163", col_names=TRUE,col_types='guess', na="NA")
library(readxl)
library(xlsx)
library(KoNLP)
library(rJava)
library(tm)
detach("package:KoNLP", unload = TRUE)
library(KoNLP)
library(tidytext)
library(dplyr)
library(wordcloud)
library(htmlwidgets)
library(topicmodels)
library(LDAvis)
library(ggplot2)
news_nov_body<-read_excel("newtro.xlsx", sheet="sheet" ,range="Q2:Q163", col_names=TRUE,col_types='guess', na="NA")
news_nov_body_line<-as.matrix(news_nov_body)
news_nov_body_line<-gsub(",","",news_nov_body_line)
news_nov_corpus<-Corpus(VectorSource(news_nov_body_line))
news_nov_dtm2<-DocumentTermMatrix(news_nov_corpus, control=list(removePunctuation=TRUE, removeNumbers=TRUE,WordLengths=c(4,40), weighting=weightTf))
Encoding(news_nov_dtm2$dimnames$Terms) = 'UTF-8'
harmonicMean <- function(logLikelihoods, precision=2000L) {
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods, prec=precision) + llMed))))
}
seqk <- seq(2, 40, 1)
burnin <- 1000
iter <- 1000
keep <- 50
fitted_many <- lapply(seqk, function(k) LDA(news_nov_dtm2, k=k, method="Gibbs",
control=list(burnin=burnin, iter=iter, keep=keep)))
logLiks_many <- lapply(fitted_many, function(L) L@logLiks[-c(1:(burnin/keep))])
hm_many <- sapply(logLiks_many, function(h) harmonicMean(h))
ggplot(data.frame(seqk, hm_many), aes(x=seqk, y=hm_many)) +
geom_path(lwd=1.5) +
theme(text=element_text(family=NULL),
axis.title.y=element_text(vjust=1, size=16),
axis.title.x=element_text(vjust=-.5, size=16),
axis.text=element_text(size=16),
plot.title=element_text(size=20)) +
xlab('Number of Topics') +
ylab('Harmonic Mean') +
ggplot2::annotate("text", x=9, y=-199000, label=paste("The optimal number of topics is", seqk[which.max(hm_many)])) +
labs(title="Latent Dirichlet Allocation Analysis",
subtitle="How many distinct topics?")
setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/뉴트로")
setwd("C:/Users/User/Desktop/빅데이터와소비자트렌드/뉴트로")
.libPaths()
.libPaths("C:/rtools42")
.libPaths()
library(rJava)
library(tm)
library(KoNLP)
library(tidytext)
library(dplyr)
library(wordcloud)
library(readxl)
library(xlsx)
library(htmlwidgets)
library(LDAvis)
library(ggplot2)
library(stringi)
library(stringr)
library(servr)
library(Rmpfr)
news_nov_body<-read_excel("newtro.xlsx", sheet="sheet" ,range="Q2:Q449", col_names=TRUE,col_types='guess', na="NA")
news_nov_body<-read_excel("newtro.xlsx", sheet="sheet" ,range="Q2:Q449", col_names=TRUE,col_types='guess', na="NA")
news_nov_body<-read_excel("newtro.xlsx", sheet="sheet" ,range="Q2:Q449", col_names=TRUE,col_types='guess', na="NA")
